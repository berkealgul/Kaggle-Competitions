{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# apply label encoding to object columns\n",
    "# train\n",
    "object_columns = df_train.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for col in object_columns:\n",
    "    df_train[col] = label_encoder.fit_transform(df_train[col])\n",
    "# test\n",
    "object_columns1 = df_test.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for col in object_columns1:\n",
    "    df_test[col] = label_encoder.fit_transform(df_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        lr = 0.00025\n",
    "        fc1_dims = 64\n",
    "        fc2_dims = 32\n",
    "        fc3_dims = 16\n",
    "        fc4_dims = 8\n",
    "        input_dims = 18\n",
    "        self.num_classes = 3\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dims, fc1_dims)\n",
    "        self.fc2 = nn.Linear(fc1_dims, fc2_dims)\n",
    "        self.fc3 = nn.Linear(fc2_dims, fc3_dims)\n",
    "        self.fc4 = nn.Linear(fc3_dims, fc4_dims)\n",
    "        self.out = nn.Linear(fc4_dims, self.num_classes)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        self.device = T.device(\"cuda:0\" if T.cuda.is_available() else \"cpu\")\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        p = self.fc1(input)\n",
    "        p = F.dropout(p, 0.3)\n",
    "        p = F.gelu(p)\n",
    "        p = self.fc2(p)\n",
    "        p = F.dropout(p, 0.3)\n",
    "        p = F.gelu(p)\n",
    "        p = self.fc3(p)\n",
    "        p = F.dropout(p, 0.3)\n",
    "        p = F.gelu(p)\n",
    "        p = self.fc4(p)\n",
    "        p = F.gelu(p)\n",
    "        p = self.out(p)\n",
    "        p = F.softmax(p)\n",
    "        return p\n",
    "    \n",
    "    def train_batch(self, x, y):\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        p = self.forward(x)\n",
    "        self.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.loss(p, y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.eval()\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "y = df_train['Status']\n",
    "x = df_train.drop(['Status', 'id'],axis=1)\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "y = y.to_numpy().reshape(-1, 1)\n",
    "enc.fit(y)\n",
    "y = enc.transform(y).toarray()\n",
    "x = x.to_numpy(dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TRC8DD~1.DES\\AppData\\Local\\Temp/ipykernel_9528/3523247259.py:37: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(p)\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "losses = []\n",
    "batch_size = 64\n",
    "epoch_count = 1000\n",
    "\n",
    "for i in range(epoch_count):\n",
    "    epoc_losses = []\n",
    "    for j in range(int(x.shape[0] / batch_size)):\n",
    "        x_ = T.tensor(x[j*batch_size:(j+1)*batch_size], dtype=T.float32)\n",
    "        y_ = T.tensor(y[j*batch_size:(j+1)*batch_size], dtype=T.float32)\n",
    "        epoc_losses.append(model.train_batch(x_, y_))\n",
    "    losses.append(np.mean(epoc_losses))\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TRC8DD~1.DES\\AppData\\Local\\Temp/ipykernel_16900/3523247259.py:37: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(p)\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = df_test['id']\n",
    "Status_C = []\n",
    "Status_CL = []\n",
    "Status_D = []\n",
    "\n",
    "x = df_test.drop(['id'],axis=1).to_numpy(dtype=float)\n",
    "for i in range(x.shape[0]):\n",
    "    x_ = T.tensor(x[i], dtype=T.float32)\n",
    "    p = model.forward(x_.to(model.device))\n",
    "    Status_C.append(p[0].item())\n",
    "    Status_CL.append(p[1].item())\n",
    "    Status_D.append(p[2].item())\n",
    "\n",
    "submission['Status_C'] = Status_C\n",
    "submission['Status_CL'] = Status_CL\n",
    "submission['Status_D'] = Status_D\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
